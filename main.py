
# ================= Standard Library Imports =================
import os
import sys
import time
import random
import shutil
import datetime
from pathlib import Path
import argparse

# ================= Third-Party Imports ======================
import numpy as np
import torch
import torch.nn as nn
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.nn.functional as F
from tqdm import tqdm
from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy

# ================= Project Imports ==========================
from utils.config import get_config
from utils.optimizer import build_optimizer, build_scheduler
from utils.tools import (
    AverageMeter, epoch_saving, load_checkpoint, load_checkpoint_fewshot,
    auto_resume_helper, gather_all_data, is_main_process, calculate_topk
)
from datasets.build import build_dataloader
from utils.logger import create_logger
from datasets.blending import CutmixMixupBlending
from trainers import bdc_clip
import torch._dynamo as dynamo

    


def parse_option():
    """Parse command line arguments and config file."""
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', '-cfg', required=True, type=str, default='configs/k400/32_8.yaml')
    parser.add_argument(
        "--opts",
        help="Modify config options by adding 'KEY VALUE' pairs.",
        default=None,
        nargs='+',
    )
    parser.add_argument('--output', type=str, default="exp")
    parser.add_argument('--resume', type=str)
    parser.add_argument('--finetune_fewshot', type=str, help='Path to the pretrained model for few-shot finetuning on downstream tasks.')
    parser.add_argument('--llm_json_path', type=str, help='Path to the JSON file containing prompts generated by LLMs.')
    parser.add_argument('--only_test', action='store_true')
    parser.add_argument('--batch-size', type=int)
    parser.add_argument('--accumulation-steps', type=int)
    parser.add_argument('--wise_ft', type=float, help='Wise-FT interpolation factor for model ensembling.')
    parser.add_argument("--local_rank", "--local-rank", type=int, default=-1, help='Local rank for DistributedDataParallel (DDP) training.')

    args = parser.parse_args()
    config = get_config(args)
    return args, config


def main(config):
    """Main training and evaluation loop."""
    # Prepare the dataloader
    train_data, val_data, train_loader, val_loader = build_dataloader(logger, config)
    class_names = [class_name for _, class_name in train_data.classes]

    # Initialize the model
    model = bdc_clip.returnCLIP(config, logger=logger, class_names=class_names)
    model = model.cuda()

    # Define loss function and augmentation strategy from config
    mixup_fn = None
    if config.AUG.MIXUP > 0:
        criterion = SoftTargetCrossEntropy()
        mixup_fn = CutmixMixupBlending(
            num_classes=config.DATA.NUM_CLASSES,
            smoothing=config.AUG.LABEL_SMOOTH,
            mixup_alpha=config.AUG.MIXUP,
            cutmix_alpha=config.AUG.CUTMIX,
            switch_prob=config.AUG.MIXUP_SWITCH_PROB
        )
    elif config.AUG.LABEL_SMOOTH > 0:
        criterion = LabelSmoothingCrossEntropy(smoothing=config.AUG.LABEL_SMOOTH)
    else:
        criterion = nn.CrossEntropyLoss()

    # Initialize optimizer and learning rate scheduler
    optimizer = build_optimizer(config, model)
    lr_scheduler = build_scheduler(config, optimizer, len(train_loader))

    # Wrap the model with DistributedDataParallel (DDP) for multi-GPU training
    model = torch.nn.parallel.DistributedDataParallel(
        model, device_ids=[config.LOCAL_RANK], broadcast_buffers=False, find_unused_parameters=False
    )

    # Create a gradient scaler for mixed precision training (AMP)
    scaler = torch.cuda.amp.GradScaler()
    start_epoch, max_accuracy = 0, 0.0

    # Load checkpoint if needed
    if config.TRAIN.AUTO_RESUME:
        resume_file = auto_resume_helper(config.OUTPUT)
        if resume_file:
            config.defrost()
            config.MODEL.RESUME = resume_file
            config.freeze()
            logger.info(f'auto resuming from {resume_file}')
        else:
            logger.info(f'no checkpoint found in {config.OUTPUT}, ignoring auto resume')
    if config.MODEL.RESUME:
        start_epoch, max_accuracy = load_checkpoint(config, model, scaler, optimizer, lr_scheduler, logger)
        print("*****start epoch is {}".format(start_epoch))
        if start_epoch > 1:
            logger.info("resetting epochs no and max. accuracy to 0 after loading pre-trained weights")
            max_accuracy = 0
    if config.MODEL.FINETUNE_FEWSHOT:
        start_epoch, max_accuracy = load_checkpoint_fewshot(config, model, logger)
        print("*****start epoch is {}".format(start_epoch))
        if start_epoch > 1:
            logger.info("resetting epochs no and max. accuracy to 0 after loading pre-trained weights")
            start_epoch = 0
            max_accuracy = 0

    # Perform testing only
    if config.TEST.ONLY_TEST:
        multi_view_inference = config.TEST.MULTI_VIEW_INFERENCE
        if multi_view_inference:
            config.defrost()
            config.TEST.NUM_CLIP = 2
            config.TEST.NUM_CROP = 1
            config.freeze()
            train_data, val_data, train_loader, val_loader = build_dataloader(logger, config)
        _,_,_ = validate(val_loader, model, config)
        return
    
    # Use torch.compile during pre-training
    if config.TRAIN.IS_PRETRAIN:
        model = torch.compile(model, mode='default')
    
    # Perform training
    for epoch in range(start_epoch, config.TRAIN.EPOCHS):
        train_loader.sampler.set_epoch(epoch)
        train_one_epoch(epoch,  scaler, model, criterion, optimizer, lr_scheduler, train_loader, config, mixup_fn)

        # validation and save
        if (epoch % config.SAVE_FREQ == 0) or epoch == (config.TRAIN.EPOCHS - 1):
            if not config.TRAIN.IS_PRETRAIN:
                _,top1_acc,_ = validate(val_loader, model, config)
                is_best = top1_acc > max_accuracy
                max_accuracy = max(max_accuracy, top1_acc)
                logger.info(f'Max accuracy: {max_accuracy:.2f}%')
            else:
                is_best = False
            logger.info(f'Max accuracy: {max_accuracy:.2f}%')
            if dist.get_rank() == 0 and (epoch % config.SAVE_FREQ == 0 or epoch == (config.TRAIN.EPOCHS - 1) or is_best):
                epoch_saving(config, epoch, model, scaler, max_accuracy, optimizer, lr_scheduler, logger, config.OUTPUT, is_best)

    # Now doing the multi-view inference crop for videos when necessary
    # 4 CLIPs are obtained from each video, and for each CLIP, we get 3 crops (augmentations)
    multi_view_inference = config.TEST.MULTI_VIEW_INFERENCE
    if multi_view_inference:
        config.defrost()
        config.TEST.NUM_CLIP = 4
        config.TEST.NUM_CROP = 3
        config.freeze()
        train_data, val_data, train_loader, val_loader = build_dataloader(logger, config)
        acc1 = validate(val_loader, model, config)
        logger.info(f"Accuracy of the network on the {len(val_data)} test videos: {acc1:.1f}%")


def train_one_epoch(epoch, scaler, model, criterion, optimizer, lr_scheduler, train_loader, config, mixup_fn):
    """Train model for one epoch."""
    model.train()
    optimizer.zero_grad()
    num_steps = len(train_loader)

    batch_time = AverageMeter()
    loss_meter_tot = AverageMeter()
    loss_meter_cls = AverageMeter()
    loss_meter_cos_vl = AverageMeter()
    loss_meter_bdc_vl = AverageMeter()
    top1_meter_cos_vl = AverageMeter()
    top5_meter_cos_vl = AverageMeter()
    top1_meter_cls = AverageMeter()
    top5_meter_cls = AverageMeter()
    top1_meter_bdc_vl = AverageMeter()
    top5_meter_bdc_vl = AverageMeter()

    start = time.time()
    end = time.time()

    for idx, batch_data in enumerate(train_loader):
        images = batch_data["imgs"].cuda(non_blocking=True)
        label_id_org = batch_data["label"].cuda(non_blocking=True)
        label_id_org = label_id_org.reshape(-1)
        images = images.view((-1, config.DATA.NUM_FRAMES, 3) + images.size()[-2:])

        if mixup_fn is not None:
            images, label_id = mixup_fn(images, label_id_org)
        else:
            label_id = label_id_org

        with torch.cuda.amp.autocast(enabled=True):
            output_cos_vl, output_cls, output_bdc_vl = model(images)
            loss_cls = criterion(output_cls, label_id)
            loss_cos_vl = criterion(output_cos_vl, label_id)
            loss_bdc_vl = criterion(output_bdc_vl, label_id)
            total_loss = (loss_cos_vl + loss_cls + loss_bdc_vl) / config.TRAIN.ACCUMULATION_STEPS

        top1_cos_vl, top5_cos_vl = calculate_topk(output_cos_vl, label_id_org)
        top1_cls, top5_cls = calculate_topk(output_cls, label_id_org)
        top1_bdc_vl, top5_bdc_vl = calculate_topk(output_bdc_vl, label_id_org)

        if config.TRAIN.ACCUMULATION_STEPS == 1:
            optimizer.zero_grad()
        if config.TRAIN.OPT_LEVEL != 'O0':
            scaler.scale(total_loss).backward()
        else:
            total_loss.backward()

        if config.TRAIN.ACCUMULATION_STEPS > 1:
            if (idx + 1) % config.TRAIN.ACCUMULATION_STEPS == 0:
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()
                lr_scheduler.step_update(epoch * num_steps + idx)
        else:
            scaler.step(optimizer)
            scaler.update()
            lr_scheduler.step_update(epoch * num_steps + idx)

        torch.cuda.synchronize()
        loss_meter_tot.update(round(total_loss.item(), 3), len(label_id))
        loss_meter_cos_vl.update(round(loss_cos_vl.item(), 3), len(label_id))
        loss_meter_cls.update(round(loss_cls.item(), 3), len(label_id))
        loss_meter_bdc_vl.update(round(loss_bdc_vl.item(), 3), len(label_id))
        top1_meter_cos_vl.update(round(top1_cos_vl.item(), 1), 1)
        top5_meter_cos_vl.update(round(top5_cos_vl.item(), 1), 1)
        top1_meter_cls.update(round(top1_cls.item(), 1), 1)
        top5_meter_cls.update(round(top5_cls.item(), 1), 1)
        top1_meter_bdc_vl.update(round(top1_bdc_vl.item(), 1), 1)
        top5_meter_bdc_vl.update(round(top5_bdc_vl.item(), 1), 1)

        batch_time.update(time.time() - end)
        end = time.time()

        if idx % config.PRINT_FREQ == 0:
            lr = optimizer.param_groups[0]['lr']
            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)
            etas = batch_time.avg * (num_steps - idx)
            logger.info(
                f'Train: [{epoch}/{config.TRAIN.EPOCHS}][{idx}/{num_steps}]|'
                f'eta {datetime.timedelta(seconds=int(etas))} lr {lr:.4f}|'
                f'time {batch_time.val:.2f} ({batch_time.avg:.4f})|'
                f'tot_loss {loss_meter_cls.val:.2f} ({loss_meter_cls.avg:.2f})|'
                f'mem {memory_used:.0f}MB|'
                f'cos_vl_Top1 {top1_meter_cos_vl.avg:.2f}|'
                f'cos_vl_Top5 {top5_meter_cos_vl.avg:.2f}|'
                f'cos_vl_loss {loss_meter_cos_vl.avg:.2f}|'
                f'cls_loss {loss_meter_cls.avg:.2f}|'
                f'bdc_vl_loss {loss_meter_bdc_vl.avg:.2f}|')

    torch.cuda.empty_cache()
    epoch_time = time.time() - start
    logger.info(f"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}")
    logger.info(f"EPOCH {epoch} training statics: Tot_loss {loss_meter_tot.avg:.2f}, cos_vl_loss {loss_meter_cos_vl.avg:.2f}, cls_loss {loss_meter_cls.avg:.2f}, bdc_vl_loss {loss_meter_bdc_vl.avg:.2f}")
    logger.info(f"EPOCH {epoch} training statics: cos_vl_Top1 {top1_meter_cos_vl.avg:.2f}, cos_vl_Top5 {top5_meter_cos_vl.avg:.2f} cls_Top1 {top1_meter_cls.avg:.2f}, cls_Top5 {top5_meter_cls.avg:.2f}, bdc_vl_Top1 {top1_meter_bdc_vl.avg:.2f}, bdc_vl_Top5 {top5_meter_bdc_vl.avg:.2f}")




@torch.no_grad()
def validate(val_loader, model, config):
    """Evaluate model on validation set."""
    model.eval()
    criterion = nn.CrossEntropyLoss()
    acc1_meter, acc5_meter, loss_meter = AverageMeter(), AverageMeter(), AverageMeter()
    total_pred_backbone, total_labels = [], []
    total_pred_bdc_vis, total_pred_bdc_algin = [], []
    logger.info(f"{config.TEST.NUM_CLIP * config.TEST.NUM_CROP} views inference")
    logger.info(f"Validation set: {config.DATA.VAL_FILE}")
    logger.info(f"LLM prompt: {config.DATA.LLM_JSON}")
    loader = tqdm(val_loader, desc="Validation") if is_main_process() else val_loader
    for idx, batch_data in enumerate(loader):
        _image = batch_data["imgs"]
        label_id = batch_data["label"]
        label_id = label_id.reshape(-1)

        b, tn, c, h, w = _image.size()
        t = config.DATA.NUM_FRAMES
        n = tn // t
        _image = _image.view(b, n, t, c, h, w)

        batch_pred_backbone = torch.zeros((b, config.DATA.NUM_CLASSES)).cuda()
        batch_pred_bdc_vis = torch.zeros((b, config.DATA.NUM_CLASSES)).cuda()
        batch_pred_bdc_algin = torch.zeros((b, config.DATA.NUM_CLASSES)).cuda()

        for i in range(n):
            image = _image[:, i, :, :, :, :]
            label_id = label_id.cuda(non_blocking=True)
            image_input = image.cuda(non_blocking=True)

            if config.TRAIN.OPT_LEVEL == 'O2':
                image_input = image_input.half()
            with torch.cuda.amp.autocast():
                logits_backbone, logits_bdc_vis, logits_bdc_algin = model(image_input)

            loss = criterion(logits_backbone, label_id)
            loss_meter.update(round(loss.item(), 3), b)

            pred_backbone = logits_backbone.view(b, -1).softmax(dim=-1)
            batch_pred_backbone += pred_backbone

            pred_bdc_vis = logits_bdc_vis.view(b, -1).softmax(dim=-1)
            batch_pred_bdc_vis += pred_bdc_vis

            pred_bdc_algin = logits_bdc_algin.view(b, -1).softmax(dim=-1)
            batch_pred_bdc_algin += pred_bdc_algin

        total_pred_backbone.append(batch_pred_backbone)
        total_pred_bdc_vis.append(batch_pred_bdc_vis)
        total_pred_bdc_algin.append(batch_pred_bdc_algin)
        total_labels.append(label_id)

    total_pred_backbone_ = torch.cat(total_pred_backbone, dim=0)
    total_pred_bdc_vis_ = torch.cat(total_pred_bdc_vis, dim=0)
    total_pred_bdc_algin_ = torch.cat(total_pred_bdc_algin, dim=0)
    total_labels_ = torch.cat(total_labels, dim=0)

    total_pred_backbone = gather_all_data(total_pred_backbone_)
    total_pred_bdc_vis = gather_all_data(total_pred_bdc_vis_)
    total_pred_bdc_algin = gather_all_data(total_pred_bdc_algin_)
    total_labels = gather_all_data(total_labels_)

    if config.TEST.TYPE == "ZEROSHOT_VAL": #For zero-shot evaluation or evaluation on the novel set in base-to-novel
        all_logits_fuse = config.TEST.COEF_BB * total_pred_backbone + config.TEST.COEF_VL * total_pred_bdc_algin
    else:
        all_logits_fuse = (
            config.TEST.COEF_BB * total_pred_backbone +
            config.TEST.COEF_VIS * total_pred_bdc_vis +
            config.TEST.COEF_VL * total_pred_bdc_algin
        )
        
    top1_correct = (total_labels == all_logits_fuse.topk(1, dim=-1)[1].squeeze(-1)).sum().item()
    top5_correct = (total_labels.unsqueeze(-1) == all_logits_fuse.topk(5, dim=-1)[1]).sum().item()
    acc1 = top1_correct / total_labels.size(0) * 100
    acc5 = top5_correct / total_labels.size(0) * 100
    acc1_meter.update(acc1, total_labels.size(0))
    acc5_meter.update(acc5, total_labels.size(0))
    loss_meter.sync()
    print(config.DATA.VAL_FILE)
    logger.info(f"Evaluation Top-1 Accuracy: {acc1_meter.avg:.1f}, Top-5 Accuracy: {acc5_meter.avg:.1f}")
    return loss_meter.avg, acc1_meter.avg, acc5_meter.avg



if __name__ == '__main__':
    """Script entry point: parse config, initialize distributed, set up logger, and run main."""
    # Prepare config
    args, config = parse_option()

    # Init distributed
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ["RANK"])
        world_size = int(os.environ['WORLD_SIZE'])
        print(f"RANK and WORLD_SIZE in environ: {rank}/{world_size}")
    else:
        rank = -1
        world_size = -1
    torch.cuda.set_device(args.local_rank)
    torch.distributed.init_process_group(backend='nccl', init_method='env://', world_size=world_size, rank=rank)
    torch.distributed.barrier(device_ids=[args.local_rank])

    # Set random seed for reproducibility
    seed = config.SEED + dist.get_rank()
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    cudnn.benchmark = True

    # Create working directory
    Path(config.OUTPUT).mkdir(parents=True, exist_ok=True)

    # Set up logger
    global logger
    logger = create_logger(output_dir=config.OUTPUT, dist_rank=dist.get_rank(), name=f"{config.MODEL.ARCH}")
    logger.info(f"working dir: {config.OUTPUT}")

    # Save config
    if dist.get_rank() == 0:
        logger.info(config)
        shutil.copy(args.config, config.OUTPUT)

    main(config)